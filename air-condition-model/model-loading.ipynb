{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T16:49:18.900837Z",
     "start_time": "2024-06-02T16:49:18.898285Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T16:49:18.906474Z",
     "start_time": "2024-06-02T16:49:18.903430Z"
    }
   },
   "source": [
    "class AirModelGRU(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=3, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, dropout=0.2)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.gru(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T16:49:18.917362Z",
     "start_time": "2024-06-02T16:49:18.910399Z"
    }
   },
   "source": [
    "def create_dataset(dataset, lookback):\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset) - lookback):\n",
    "        feature = dataset[i:i + lookback]\n",
    "        target = dataset[i + 1:i + lookback + 1]\n",
    "        X.append(feature)\n",
    "        y.append(target)\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    y = np.array(y, dtype=np.float32)\n",
    "    return torch.tensor(X), torch.tensor(y)\n",
    "\n",
    "train_data = np.load('train_data.npy')\n",
    "test_data = np.load('test_data.npy')\n",
    "\n",
    "lookback = 3\n",
    "X_train, y_train = create_dataset(train_data, lookback)\n",
    "X_test, y_test = create_dataset(test_data, lookback)\n",
    "\n",
    "\n",
    "train_data = np.load('train_data.npy')\n",
    "test_data = np.load('test_data.npy')"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T16:49:18.920356Z",
     "start_time": "2024-06-02T16:49:18.918567Z"
    }
   },
   "source": [
    "hidden_size = 100\n",
    "num_layers = 2\n",
    "n_epochs = 10"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T16:49:18.922636Z",
     "start_time": "2024-06-02T16:49:18.921044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([928, 3])\n",
      "torch.Size([456, 3])\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T16:50:24.553529Z",
     "start_time": "2024-06-02T16:50:22.882480Z"
    }
   },
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = AirModelGRU(hidden_size, num_layers).to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loader = DataLoader(TensorDataset(X_train, y_train), shuffle=True, batch_size=8)\n",
    "\n",
    "for epoch in tqdm(range(n_epochs), desc=\"Training epochs\"):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in loader:\n",
    "        X, y = batch[0].to(device), batch[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * X.size(0)\n",
    "    \n",
    "    train_loss /= len(loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), 'GRU.pth')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test.to(device))\n",
    "    print(\"Predictions:\", predictions.cpu().numpy())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  20%|██        | 2/10 [00:00<00:01,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.0159\n",
      "Epoch 2, Train Loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  40%|████      | 4/10 [00:00<00:00,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.0060\n",
      "Epoch 4, Train Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  60%|██████    | 6/10 [00:01<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.0058\n",
      "Epoch 6, Train Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  80%|████████  | 8/10 [00:01<00:00,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.0057\n",
      "Epoch 8, Train Loss: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs: 100%|██████████| 10/10 [00:01<00:00,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.0058\n",
      "Epoch 10, Train Loss: 0.0059\n",
      "Predictions: [[0.16595298]\n",
      " [0.14492118]\n",
      " [0.11124821]\n",
      " [0.12755835]\n",
      " [0.15140331]\n",
      " [0.14904061]\n",
      " [0.17407887]\n",
      " [0.16580996]\n",
      " [0.10938173]\n",
      " [0.06700751]\n",
      " [0.07456356]\n",
      " [0.08974874]\n",
      " [0.06919913]\n",
      " [0.08472256]\n",
      " [0.13997686]\n",
      " [0.14995064]\n",
      " [0.10490574]\n",
      " [0.08587183]\n",
      " [0.11056449]\n",
      " [0.1301845 ]\n",
      " [0.13481647]\n",
      " [0.1402328 ]\n",
      " [0.11844417]\n",
      " [0.12426402]\n",
      " [0.12407767]\n",
      " [0.09012716]\n",
      " [0.09185787]\n",
      " [0.1560015 ]\n",
      " [0.20876357]\n",
      " [0.1891048 ]\n",
      " [0.16098657]\n",
      " [0.18274081]\n",
      " [0.19925293]\n",
      " [0.18645525]\n",
      " [0.18797582]\n",
      " [0.20766875]\n",
      " [0.19699821]\n",
      " [0.13731655]\n",
      " [0.14673758]\n",
      " [0.21116811]\n",
      " [0.14989263]\n",
      " [0.14615059]\n",
      " [0.2612579 ]\n",
      " [0.34810373]\n",
      " [0.39104864]\n",
      " [0.22278059]\n",
      " [0.22204852]\n",
      " [0.25416723]\n",
      " [0.36890146]\n",
      " [0.38653302]\n",
      " [0.3243063 ]\n",
      " [0.4169311 ]\n",
      " [0.5825616 ]\n",
      " [0.50392884]\n",
      " [0.22165775]\n",
      " [0.08309871]\n",
      " [0.05449853]\n",
      " [0.07802507]\n",
      " [0.07881817]\n",
      " [0.07664399]\n",
      " [0.07307972]\n",
      " [0.08998635]\n",
      " [0.08115945]\n",
      " [0.08084051]\n",
      " [0.11488898]\n",
      " [0.12285519]\n",
      " [0.11932077]\n",
      " [0.09900872]\n",
      " [0.07275415]\n",
      " [0.07739486]\n",
      " [0.07005325]\n",
      " [0.05748412]\n",
      " [0.07320068]\n",
      " [0.06452981]\n",
      " [0.06918976]\n",
      " [0.05668836]\n",
      " [0.07082875]\n",
      " [0.10364155]\n",
      " [0.0872422 ]\n",
      " [0.07646865]\n",
      " [0.06738116]\n",
      " [0.05699152]\n",
      " [0.07309279]\n",
      " [0.08421133]\n",
      " [0.07084423]\n",
      " [0.06717529]\n",
      " [0.07389382]\n",
      " [0.08204202]\n",
      " [0.09024201]\n",
      " [0.08364503]\n",
      " [0.0586217 ]\n",
      " [0.04633334]\n",
      " [0.06947038]\n",
      " [0.06896961]\n",
      " [0.05229204]\n",
      " [0.05036668]\n",
      " [0.07716689]\n",
      " [0.0721281 ]\n",
      " [0.06245957]\n",
      " [0.05122532]\n",
      " [0.0601734 ]\n",
      " [0.08788222]\n",
      " [0.07576191]\n",
      " [0.08756062]\n",
      " [0.09035454]\n",
      " [0.07162671]\n",
      " [0.0524935 ]\n",
      " [0.05540704]\n",
      " [0.07025087]\n",
      " [0.08657277]\n",
      " [0.06841493]\n",
      " [0.05969269]\n",
      " [0.07556693]\n",
      " [0.0944254 ]\n",
      " [0.09632973]\n",
      " [0.11903273]\n",
      " [0.12817442]\n",
      " [0.08776097]\n",
      " [0.08908306]\n",
      " [0.11051934]\n",
      " [0.0735851 ]\n",
      " [0.04843374]\n",
      " [0.04994942]\n",
      " [0.07738274]\n",
      " [0.0722701 ]\n",
      " [0.06255724]\n",
      " [0.09576222]\n",
      " [0.11091039]\n",
      " [0.13538876]\n",
      " [0.10999224]\n",
      " [0.06438404]\n",
      " [0.05190707]\n",
      " [0.06267999]\n",
      " [0.06373403]\n",
      " [0.0516719 ]\n",
      " [0.06027188]\n",
      " [0.06813131]\n",
      " [0.13381878]\n",
      " [0.16112973]\n",
      " [0.08638051]\n",
      " [0.05244642]\n",
      " [0.04270675]\n",
      " [0.0621308 ]\n",
      " [0.10055527]\n",
      " [0.11660317]\n",
      " [0.09871439]\n",
      " [0.08733447]\n",
      " [0.11563948]\n",
      " [0.12791356]\n",
      " [0.08289944]\n",
      " [0.2780759 ]\n",
      " [0.5218437 ]\n",
      " [0.3227174 ]\n",
      " [0.11342013]\n",
      " [0.05195348]\n",
      " [0.06132178]\n",
      " [0.09951808]\n",
      " [0.12229892]\n",
      " [0.14688501]\n",
      " [0.21363077]\n",
      " [0.2814267 ]\n",
      " [0.245226  ]\n",
      " [0.24382031]\n",
      " [0.23216873]\n",
      " [0.16077097]\n",
      " [0.10002539]\n",
      " [0.1006956 ]\n",
      " [0.10016271]\n",
      " [0.09059672]\n",
      " [0.07694927]\n",
      " [0.07554726]\n",
      " [0.07752466]\n",
      " [0.0826847 ]\n",
      " [0.08549303]\n",
      " [0.19084123]\n",
      " [0.20060784]\n",
      " [0.13528469]\n",
      " [0.12097825]\n",
      " [0.10653506]\n",
      " [0.08614573]\n",
      " [0.088771  ]\n",
      " [0.08378035]\n",
      " [0.14832464]\n",
      " [0.2480346 ]\n",
      " [0.29156318]\n",
      " [0.24417007]\n",
      " [0.26350832]\n",
      " [0.49194753]\n",
      " [0.7003647 ]\n",
      " [0.77631545]\n",
      " [0.78212655]\n",
      " [0.6484132 ]\n",
      " [0.5799916 ]\n",
      " [0.7295631 ]\n",
      " [0.8465689 ]\n",
      " [0.7456381 ]\n",
      " [0.6656209 ]\n",
      " [0.47183368]\n",
      " [0.29999802]\n",
      " [0.19081596]\n",
      " [0.22324279]\n",
      " [0.31908432]\n",
      " [0.32024232]\n",
      " [0.35424972]\n",
      " [0.39492863]\n",
      " [0.31185064]\n",
      " [0.3694825 ]\n",
      " [0.34976068]\n",
      " [0.40022585]\n",
      " [0.40780964]\n",
      " [0.20243913]\n",
      " [0.14666717]\n",
      " [0.14144751]\n",
      " [0.11588919]\n",
      " [0.17005959]\n",
      " [0.1260826 ]\n",
      " [0.2042515 ]\n",
      " [0.2570199 ]\n",
      " [0.32954887]\n",
      " [0.3987591 ]\n",
      " [0.34063098]\n",
      " [0.27849582]\n",
      " [0.21711907]\n",
      " [0.18482727]\n",
      " [0.25900584]\n",
      " [0.22849602]\n",
      " [0.2361167 ]\n",
      " [0.20183873]\n",
      " [0.15856016]\n",
      " [0.1459345 ]\n",
      " [0.20465177]\n",
      " [0.15893579]\n",
      " [0.13220142]\n",
      " [0.22528812]\n",
      " [0.25212434]\n",
      " [0.17482555]\n",
      " [0.1877658 ]\n",
      " [0.18443021]\n",
      " [0.26127887]\n",
      " [0.23523727]\n",
      " [0.1791814 ]\n",
      " [0.18241633]\n",
      " [0.1674539 ]\n",
      " [0.21439469]\n",
      " [0.22175497]\n",
      " [0.23655239]\n",
      " [0.23425058]\n",
      " [0.20761484]\n",
      " [0.16553757]\n",
      " [0.08784872]\n",
      " [0.13501254]\n",
      " [0.21964365]\n",
      " [0.1976941 ]\n",
      " [0.20204234]\n",
      " [0.17118381]\n",
      " [0.13267979]\n",
      " [0.10106236]\n",
      " [0.12295857]\n",
      " [0.14644086]\n",
      " [0.15655893]\n",
      " [0.17473021]\n",
      " [0.17871645]\n",
      " [0.16706118]\n",
      " [0.12650254]\n",
      " [0.1452972 ]\n",
      " [0.18071888]\n",
      " [0.13741936]\n",
      " [0.13176891]\n",
      " [0.1721197 ]\n",
      " [0.13629705]\n",
      " [0.1020558 ]\n",
      " [0.10999476]\n",
      " [0.12802497]\n",
      " [0.14964096]\n",
      " [0.16888335]\n",
      " [0.20565146]\n",
      " [0.18377444]\n",
      " [0.1830447 ]\n",
      " [0.22183311]\n",
      " [0.24532208]\n",
      " [0.24036404]\n",
      " [0.32570347]\n",
      " [0.5334991 ]\n",
      " [0.5028187 ]\n",
      " [0.34478632]\n",
      " [0.26743352]\n",
      " [0.25376168]\n",
      " [0.4001344 ]\n",
      " [0.4647586 ]\n",
      " [0.5103742 ]\n",
      " [0.39588195]\n",
      " [0.3953319 ]\n",
      " [0.40813762]\n",
      " [0.41178802]\n",
      " [0.27727422]\n",
      " [0.1933248 ]\n",
      " [0.1549168 ]\n",
      " [0.14455715]\n",
      " [0.13514704]\n",
      " [0.12924674]\n",
      " [0.12317603]\n",
      " [0.1398561 ]\n",
      " [0.2564112 ]\n",
      " [0.28168786]\n",
      " [0.24924007]\n",
      " [0.1964297 ]\n",
      " [0.24196815]\n",
      " [0.24907023]\n",
      " [0.15290177]\n",
      " [0.11682176]\n",
      " [0.10908441]\n",
      " [0.08921313]\n",
      " [0.07963326]\n",
      " [0.13302365]\n",
      " [0.15929966]\n",
      " [0.17511341]\n",
      " [0.18351959]\n",
      " [0.18966478]\n",
      " [0.17778358]\n",
      " [0.14493504]\n",
      " [0.16431832]\n",
      " [0.18259108]\n",
      " [0.16013749]\n",
      " [0.15087193]\n",
      " [0.19186512]\n",
      " [0.18505761]\n",
      " [0.15591902]\n",
      " [0.18009782]\n",
      " [0.20402873]\n",
      " [0.18935418]\n",
      " [0.18338633]\n",
      " [0.20484236]\n",
      " [0.2567025 ]\n",
      " [0.34122217]\n",
      " [0.58097357]\n",
      " [0.7020375 ]\n",
      " [0.46597448]\n",
      " [0.49111405]\n",
      " [0.6295196 ]\n",
      " [0.37147856]\n",
      " [0.17159092]\n",
      " [0.10107948]\n",
      " [0.09809209]\n",
      " [0.15928283]\n",
      " [0.18058708]\n",
      " [0.1980389 ]\n",
      " [0.16389078]\n",
      " [0.09031025]\n",
      " [0.08250962]\n",
      " [0.09796822]\n",
      " [0.1272035 ]\n",
      " [0.1517266 ]\n",
      " [0.11467206]\n",
      " [0.12915817]\n",
      " [0.13406599]\n",
      " [0.13815147]\n",
      " [0.11324963]\n",
      " [0.07212871]\n",
      " [0.0850222 ]\n",
      " [0.07070251]\n",
      " [0.07517893]\n",
      " [0.11927732]\n",
      " [0.14066085]\n",
      " [0.17305042]\n",
      " [0.14578104]\n",
      " [0.1370982 ]\n",
      " [0.18754393]\n",
      " [0.15465844]\n",
      " [0.08442533]\n",
      " [0.05198365]\n",
      " [0.06557758]\n",
      " [0.16661718]\n",
      " [0.26950938]\n",
      " [0.15044522]\n",
      " [0.05137151]\n",
      " [0.05502947]\n",
      " [0.16840565]\n",
      " [0.18166757]\n",
      " [0.3650132 ]\n",
      " [0.5143694 ]\n",
      " [0.29304537]\n",
      " [0.21308807]\n",
      " [0.3370574 ]\n",
      " [0.21112043]\n",
      " [0.14507121]\n",
      " [0.1313383 ]\n",
      " [0.21213397]\n",
      " [0.21132135]\n",
      " [0.1102716 ]\n",
      " [0.17465824]\n",
      " [0.16979742]\n",
      " [0.0864823 ]\n",
      " [0.07465321]\n",
      " [0.12958923]\n",
      " [0.27815494]\n",
      " [0.27799115]\n",
      " [0.12969175]\n",
      " [0.0410202 ]\n",
      " [0.03719287]\n",
      " [0.17503965]\n",
      " [0.19426394]\n",
      " [0.09830086]\n",
      " [0.0465136 ]\n",
      " [0.1573559 ]\n",
      " [0.33740434]\n",
      " [0.39061698]\n",
      " [0.47525883]\n",
      " [0.5473768 ]\n",
      " [0.37503567]\n",
      " [0.2530593 ]\n",
      " [0.13130914]\n",
      " [0.07172053]\n",
      " [0.05884004]\n",
      " [0.05027419]\n",
      " [0.03654055]\n",
      " [0.06945503]\n",
      " [0.0567638 ]\n",
      " [0.05895668]\n",
      " [0.1275771 ]\n",
      " [0.23873374]\n",
      " [0.14659983]\n",
      " [0.07237764]\n",
      " [0.04712413]\n",
      " [0.03320558]\n",
      " [0.03889934]\n",
      " [0.04904541]\n",
      " [0.03282703]\n",
      " [0.03137529]\n",
      " [0.03559095]\n",
      " [0.05099749]\n",
      " [0.04978839]\n",
      " [0.04021446]\n",
      " [0.03662214]\n",
      " [0.05100046]\n",
      " [0.05471827]\n",
      " [0.06280807]\n",
      " [0.0584273 ]\n",
      " [0.0731459 ]\n",
      " [0.07907272]\n",
      " [0.07767776]\n",
      " [0.07248329]\n",
      " [0.10428725]\n",
      " [0.09440842]\n",
      " [0.13926896]\n",
      " [0.30826044]\n",
      " [0.49967992]\n",
      " [0.31612363]\n",
      " [0.13815874]\n",
      " [0.09620354]\n",
      " [0.10040211]\n",
      " [0.05883305]\n",
      " [0.04281293]\n",
      " [0.04982416]\n",
      " [0.04806031]\n",
      " [0.04037654]\n",
      " [0.04186809]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 36
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
